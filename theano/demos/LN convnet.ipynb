{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling_window(a, window):\n",
    "    \"\"\"\n",
    "    Make an ndarray with a rolling window of the last dimension\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Array to add rolling window to\n",
    "    window : int\n",
    "        Size of rolling window\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Array that is a view of the original array with a added dimension\n",
    "    of size w.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> x=np.arange(10).reshape((2,5))\n",
    "    >>> rolling_window(x, 3)\n",
    "    array([[[0, 1, 2], [1, 2, 3], [2, 3, 4]],\n",
    "           [[5, 6, 7], [6, 7, 8], [7, 8, 9]]])\n",
    "\n",
    "    Calculate rolling mean of last dimension:\n",
    "\n",
    "    >>> np.mean(rolling_window(x, 3), -1)\n",
    "    array([[ 1.,  2.,  3.],\n",
    "           [ 6.,  7.,  8.]])\n",
    "\n",
    "    \"\"\"\n",
    "    assert window >= 1, \"`window` must be at least 1.\"\n",
    "    assert window < a.shape[-1], \"`window` is too long.\"\n",
    "\n",
    "    # # with strides\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def softrect(X):\n",
    "    return T.log(1 + T.exp(X))\n",
    "\n",
    "def poiss(rhat, r, fudge=1e-8):\n",
    "    return rhat - r * T.log(rhat+fudge)\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def model(X, w1, w2):\n",
    "    l1 = rectify(conv2d(X, w1, border_mode='full'))\n",
    "    y = softrect(T.dot(T.flatten(l1, outdim=2),w2))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simulate a toy conv-LN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fake filter\n",
    "filter_dims = (5,5,10)\n",
    "xm, ym = np.meshgrid(np.linspace(-5,5,filter_dims[0]), np.linspace(-5,5,filter_dims[1]))\n",
    "\n",
    "z = xm**2 + ym**2\n",
    "z = np.abs(z.max() - z)\n",
    "\n",
    "f_star = np.outer(z, np.sin(np.linspace(0, 2*np.pi, filter_dims[2]))).reshape(5,5,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate stimulus\n",
    "num_samples = 100\n",
    "stim_size = (32,32)\n",
    "\n",
    "stim = np.random.randn(*(stim_size + (num_samples,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1 = init_weights((1,) + f_star.T.shape)\n",
    "w2 = init_weights((np.prod(stim_size),1))\n",
    "\n",
    "X = T.ftensor4()\n",
    "r = T.fvector()\n",
    "\n",
    "rhat = model(X, w1, w2)\n",
    "cost = T.mean(poiss(r,rhat))\n",
    "\n",
    "updates = RMSprop(cost, [w1,w2], lr=0.01)\n",
    "\n",
    "train = theano.function(inputs=[X,r], outputs=cost, updates=updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_star = floatX(np.zeros((np.prod(stim_size),1)))\n",
    "w_star[170,0] = 1\n",
    "pred = theano.function(inputs=[X], outputs=model(X,floatX(f_star.T.reshape(1,10,5,5,)),w_star), allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: A.shape[1] != y.shape[0]\nApply node that caused the error: CGemv{inplace}(Alloc.0, TensorConstant{1.0}, Flatten{2}.0, TensorConstant{[ 0.  0.  ...  0.  0.]}, TensorConstant{0.0})\nInputs shapes: [(1,), (), (1, 1296), (1024,), ()]\nInputs strides: [(4,), (), (5184, 4), (4,), ()]\nInputs types: [TensorType(float32, vector), TensorType(float32, scalar), TensorType(float32, matrix), TensorType(float32, vector), TensorType(float32, scalar)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9512abe81801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m                     \u001b[0;31m# For the CVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     gof.vm.raise_with_op(self.fn.nodes[self.fn.position_of_error],\n\u001b[0;32m--> 588\u001b[0;31m                                          self.fn.thunks[self.fn.position_of_error])\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0;31m# For the c linker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: A.shape[1] != y.shape[0]\nApply node that caused the error: CGemv{inplace}(Alloc.0, TensorConstant{1.0}, Flatten{2}.0, TensorConstant{[ 0.  0.  ...  0.  0.]}, TensorConstant{0.0})\nInputs shapes: [(1,), (), (1, 1296), (1024,), ()]\nInputs strides: [(4,), (), (5184, 4), (4,), ()]\nInputs types: [TensorType(float32, vector), TensorType(float32, scalar), TensorType(float32, matrix), TensorType(float32, vector), TensorType(float32, scalar)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node."
     ]
    }
   ],
   "source": [
    "stim = np.random.randn(1, 10, 32, 32)\n",
    "rhat = pred(stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost_history = list()\n",
    "for j in range(10000):\n",
    "\n",
    "    # generate spiking data\n",
    "    stim = np.rollaxis(np.rollaxis(rolling_window(stim, filter_dims[2]),3),3)\n",
    "    rhat = pred(stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy example\n",
    "w = init_weights(f_star.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.ftensor4()\n",
    "y = T.fvector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sqerr(x, y):\n",
    "    u = T.tensordot(w, x, ([0,1,2],[0,1,2]))\n",
    "    return 0.5*((y-u)**2)\n",
    "\n",
    "cost = T.mean(sqerr(x,y))\n",
    "updates = RMSprop(cost, [w], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function(inputs=[x, y], outputs=cost, updates=updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Cost = 19389.595703\n",
      "[25] Cost = 15695.724609\n",
      "[50] Cost = 13127.696289\n",
      "[75] Cost = 10532.672852\n",
      "[100] Cost = 7178.458496\n",
      "[125] Cost = 5844.898438\n",
      "[150] Cost = 3739.792236\n",
      "[175] Cost = 2879.681152\n",
      "[200] Cost = 1881.470825\n",
      "[225] Cost = 1247.353638\n",
      "[250] Cost = 771.851990\n",
      "[275] Cost = 413.708069\n",
      "[300] Cost = 201.289230\n",
      "[325] Cost = 92.907364\n",
      "[350] Cost = 36.531059\n",
      "[375] Cost = 12.850611\n",
      "[400] Cost = 2.750138\n",
      "[425] Cost = 0.269782\n",
      "[450] Cost = 0.359387\n",
      "[475] Cost = 0.327884\n",
      "[500] Cost = 0.448778\n",
      "[525] Cost = 0.425444\n",
      "[550] Cost = 0.305991\n",
      "[575] Cost = 0.329312\n",
      "[600] Cost = 0.379528\n",
      "[625] Cost = 0.365201\n",
      "[650] Cost = 0.264057\n",
      "[675] Cost = 0.314834\n",
      "[700] Cost = 0.424314\n",
      "[725] Cost = 0.397663\n",
      "[750] Cost = 0.265900\n",
      "[775] Cost = 0.312521\n",
      "[800] Cost = 0.337047\n",
      "[825] Cost = 0.342705\n",
      "[850] Cost = 0.340496\n",
      "[875] Cost = 0.289348\n",
      "[900] Cost = 0.237004\n",
      "[925] Cost = 0.299945\n",
      "[950] Cost = 0.304594\n",
      "[975] Cost = 0.415855\n",
      "[1000] Cost = 0.447401\n",
      "[1025] Cost = 0.303455\n",
      "[1050] Cost = 0.531838\n",
      "[1075] Cost = 0.350356\n",
      "[1100] Cost = 0.281037\n",
      "[1125] Cost = 0.449284\n",
      "[1150] Cost = 0.390511\n",
      "[1175] Cost = 0.267124\n",
      "[1200] Cost = 0.462049\n",
      "[1225] Cost = 0.368232\n",
      "[1250] Cost = 0.314790\n",
      "[1275] Cost = 0.309755\n",
      "[1300] Cost = 0.407617\n",
      "[1325] Cost = 0.332293\n",
      "[1350] Cost = 0.445632\n",
      "[1375] Cost = 0.285284\n",
      "[1400] Cost = 0.300244\n",
      "[1425] Cost = 0.317583\n",
      "[1450] Cost = 0.461789\n",
      "[1475] Cost = 0.399657\n",
      "[1500] Cost = 0.355994\n",
      "[1525] Cost = 0.355577\n",
      "[1550] Cost = 0.325956\n",
      "[1575] Cost = 0.385148\n",
      "[1600] Cost = 0.363285\n",
      "[1625] Cost = 0.464740\n",
      "[1650] Cost = 0.334654\n",
      "[1675] Cost = 0.351546\n",
      "[1700] Cost = 0.323521\n",
      "[1725] Cost = 0.404063\n",
      "[1750] Cost = 0.321750\n",
      "[1775] Cost = 0.304594\n",
      "[1800] Cost = 0.358212\n",
      "[1825] Cost = 0.289236\n",
      "[1850] Cost = 0.386571\n",
      "[1875] Cost = 0.419210\n",
      "[1900] Cost = 0.347858\n",
      "[1925] Cost = 0.292573\n",
      "[1950] Cost = 0.374355\n",
      "[1975] Cost = 0.519895\n",
      "[2000] Cost = 0.443310\n",
      "[2025] Cost = 0.356384\n",
      "[2050] Cost = 0.536936\n",
      "[2075] Cost = 0.344912\n",
      "[2100] Cost = 0.322899\n",
      "[2125] Cost = 0.337540\n",
      "[2150] Cost = 0.368310\n",
      "[2175] Cost = 0.345903\n",
      "[2200] Cost = 0.349152\n",
      "[2225] Cost = 0.355644\n",
      "[2250] Cost = 0.356048\n",
      "[2275] Cost = 0.307525\n",
      "[2300] Cost = 0.331994\n",
      "[2325] Cost = 0.362575\n",
      "[2350] Cost = 0.263293\n",
      "[2375] Cost = 0.352808\n",
      "[2400] Cost = 0.496624\n",
      "[2425] Cost = 0.381757\n",
      "[2450] Cost = 0.305576\n",
      "[2475] Cost = 0.322964\n"
     ]
    }
   ],
   "source": [
    "cost_history = list()\n",
    "for j in range(2500):\n",
    "    \n",
    "    num_samples = 1000\n",
    "    \n",
    "    # generate data\n",
    "    X = np.random.randn(*(f_star.shape + (num_samples,)))\n",
    "    Y = np.tensordot(f_star, X, ([0,1,2], [0,1,2])) + 0.01*np.random.randn(num_samples)\n",
    "    \n",
    "    cost_history.append(train(X,Y))\n",
    "    \n",
    "    if j % 25 == 0:\n",
    "        print('[%i] Cost = %f' % (j, cost_history[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
